{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"/workspaces/evals/dataset\"\n",
    "system_input = \"\"\n",
    "\n",
    "def battle(system_input1, user_input1, completion1, system_input2, user_input2, completion2):\n",
    "\n",
    "    battle_path = os.path.join(os.getcwd(), \"registry\", \"data\", \"battle\")\n",
    "    os.makedirs(battle_path, exist_ok=True)\n",
    "    battle_path = os.path.join(battle_path, \"samples.jsonl\")\n",
    "\n",
    "    # Data\n",
    "    input1 = ([{\"role\":\"system\",\"content\":system_input1},{\"role\":\"user\",\"content\":user_input1}])\n",
    "    input2 = ([{\"role\":\"system\",\"content\":system_input2},{\"role\":\"user\",\"content\":user_input2}])\n",
    "    dataset = [{\"input1\": input1, \"completion1\": completion1, \"input2\": input2, \"completion2\":completion2}]\n",
    "    pd.DataFrame(dataset).to_json(battle_path, orient=\"records\", lines=True)\n",
    "    \n",
    "    # Run eval\n",
    "    !oaieval gpt-3.5-turbo battle --record_path /workspaces/evals/evallogs/logs\n",
    "    \n",
    "    # Report\n",
    "    with open(\"/workspaces/evals/evallogs/logs\", \"r\") as f:\n",
    "        events_df = pd.read_json(f, lines=True)\n",
    "\n",
    "    record_path = \"/workspaces/evals/evallogs/eval\"\n",
    "    os.makedirs(record_path, exist_ok=True)\n",
    "    events_df.to_json(os.path.join(record_path, \"events\"), lines=True, orient=\"records\")\n",
    "    events_df[\"data\"].to_json(os.path.join(record_path, \"data\"), lines=True, orient=\"records\")\n",
    "    data_df = pd.read_json(os.path.join(record_path, \"data\"), lines=True)\n",
    "    for row in data_df[0]:\n",
    "        s = str(row)\n",
    "        s = s.replace(\"[\",\"\",-1)\n",
    "        s = s.replace(\"]\",\"\",-1)\n",
    "        if s.startswith(\"{'choice':\"):\n",
    "            s = s.split(\"'\")[3]\n",
    "            choice = s\n",
    "        if s.startswith(\"{'prompt': {'role': 'user', 'content': 'You are comparing two responses to the following two instructions.\"):\n",
    "            sampled = s.split(\"\\\\n\\\\nReasoning:\\'}, \\'sampled\\': \")[1].replace(\"\\\\'\",\"'\").replace(\"\\\\n\",\"\\n\")\n",
    "    \n",
    "    data = {'Choice': choice, 'Instruction1': user_input1, 'Response1': completion1, 'Instruction2': user_input2, 'Response2': completion2, 'Sampled': sampled}\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def test_match(test_dataset):\n",
    "    \n",
    "    data = []\n",
    "    for t in range(0,len(test_dataset)):\n",
    "        data.append({\"input\":[{\"role\":\"system\",\"content\":\"\"},{\"role\":\"user\",\"content\":test_dataset[t][0]}], \"ideal\":test_dataset[t][2]})\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Paths. Assuming this notebook is in evals/evals\n",
    "\n",
    "    test_match_path = os.path.join(os.getcwd(), \"registry\", \"data\", \"match\")\n",
    "    os.makedirs(test_match_path, exist_ok=True)\n",
    "    test_match_path = os.path.join(test_match_path, \"samples.jsonl\")\n",
    "\n",
    "    df.to_json(test_match_path, orient=\"records\", lines=True)\n",
    "    \n",
    "    !oaieval gpt-3.5-turbo match --record_path /workspaces/evals/evallogs/logs\n",
    "    \n",
    "    events = \"/workspaces/evals/evallogs/logs\"\n",
    "    record_path = os.path.join(\"/workspaces/evals/evallogs/eval\")\n",
    "    with open(events, \"r\") as f:\n",
    "        events_df = pd.read_json(f, lines=True)\n",
    "    \n",
    "    os.makedirs(record_path, exist_ok=True)\n",
    "    events_df.to_json(os.path.join(record_path, \"events\"), lines=True, orient=\"records\")\n",
    "    events_df[\"data\"].to_json(os.path.join(record_path, \"data\"), lines=True, orient=\"records\")\n",
    "    data_df = pd.read_json(os.path.join(record_path, \"data\"), lines=True)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "def content_to_list(content, dataset):\n",
    "    dataset_df = pd.DataFrame(dataset)\n",
    "    return dataset[dataset_df[0].to_list().index(content)]\n",
    "\n",
    "def append_response(content, response, dataset):\n",
    "    dataset_df = pd.DataFrame(dataset)\n",
    "    index = dataset_df[0].to_list().index(content)\n",
    "    dataset[index][2].append(response)\n",
    "    return len(dataset[index][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1453/4025275403.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  battles_df = pd.read_json(os.path.join(dataset_path, \"battles\"), lines=True)\n",
      "/tmp/ipykernel_1453/4025275403.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  battles_df = pd.read_json(os.path.join(dataset_path, \"battles\"), lines=True)\n",
      "/tmp/ipykernel_1453/4025275403.py:5: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  battles_df = pd.read_json(os.path.join(dataset_path, \"battles\"), lines=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-27 07:51:08,769] [registry.py:270] Loading registry from /workspaces/evals/evals/registry/evals\n",
      "[2023-07-27 07:51:10,466] [registry.py:270] Loading registry from /home/codespace/.evals/evals\n",
      "[2023-07-27 07:51:10,468] [oaieval.py:138] \u001b[1;35mRun started: 230727075110TORUDJR5\u001b[0m\n",
      "[2023-07-27 07:51:10,476] [data.py:83] Fetching match/samples.jsonl\n",
      "[2023-07-27 07:51:10,476] [eval.py:33] Evaluating 1 samples\n",
      "[2023-07-27 07:51:10,499] [eval.py:139] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.26s/it]\n",
      "/home/codespace/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/codespace/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "[2023-07-27 07:51:14,821] [record.py:341] Final report: {'accuracy': 1.0, 'boostrap_std': nan}. Logged to /workspaces/evals/evallogs/logs\n",
      "[2023-07-27 07:51:14,821] [oaieval.py:177] Final report:\n",
      "[2023-07-27 07:51:14,821] [oaieval.py:179] accuracy: 1.0\n",
      "[2023-07-27 07:51:14,821] [oaieval.py:179] boostrap_std: nan\n",
      "[2023-07-27 07:51:14,822] [record.py:330] Logged 2 rows of events to /workspaces/evals/evallogs/logs: insert_time=0.493ms\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m     pd\u001b[39m.\u001b[39mSeries(responses)\n\u001b[1;32m     76\u001b[0m responses_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(responses, dataset_df[\u001b[39m2\u001b[39m])\n\u001b[0;32m---> 77\u001b[0m responses_df\u001b[39m.\u001b[39;49mto_json(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dataset_path, \u001b[39m\"\u001b[39;49m\u001b[39mresponses\u001b[39;49m\u001b[39m\"\u001b[39;49m), lines\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, orient\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrecords\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:2532\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m   2529\u001b[0m config\u001b[39m.\u001b[39mis_nonnegative_int(indent)\n\u001b[1;32m   2530\u001b[0m indent \u001b[39m=\u001b[39m indent \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 2532\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mto_json(\n\u001b[1;32m   2533\u001b[0m     path_or_buf\u001b[39m=\u001b[39;49mpath_or_buf,\n\u001b[1;32m   2534\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2535\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[1;32m   2536\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   2537\u001b[0m     double_precision\u001b[39m=\u001b[39;49mdouble_precision,\n\u001b[1;32m   2538\u001b[0m     force_ascii\u001b[39m=\u001b[39;49mforce_ascii,\n\u001b[1;32m   2539\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[1;32m   2540\u001b[0m     default_handler\u001b[39m=\u001b[39;49mdefault_handler,\n\u001b[1;32m   2541\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[1;32m   2542\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2543\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2544\u001b[0m     indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m   2545\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2546\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   2547\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py:181\u001b[0m, in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobj\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should be a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m s \u001b[39m=\u001b[39m writer(\n\u001b[1;32m    182\u001b[0m     obj,\n\u001b[1;32m    183\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[1;32m    184\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m    185\u001b[0m     double_precision\u001b[39m=\u001b[39;49mdouble_precision,\n\u001b[1;32m    186\u001b[0m     ensure_ascii\u001b[39m=\u001b[39;49mforce_ascii,\n\u001b[1;32m    187\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[1;32m    188\u001b[0m     default_handler\u001b[39m=\u001b[39;49mdefault_handler,\n\u001b[1;32m    189\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    190\u001b[0m     indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    191\u001b[0m )\u001b[39m.\u001b[39mwrite()\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m lines:\n\u001b[1;32m    194\u001b[0m     s \u001b[39m=\u001b[39m convert_to_line_delimits(s)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py:237\u001b[0m, in \u001b[0;36mWriter.__init__\u001b[0;34m(self, obj, orient, date_format, double_precision, ensure_ascii, date_unit, index, default_handler, indent)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent \u001b[39m=\u001b[39m indent\n\u001b[1;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_copy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format_axes()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py:292\u001b[0m, in \u001b[0;36mFrameWriter._format_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_format_axes\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    Try to format axes if they are datelike.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mis_unique \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    293\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    294\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame index must be unique for orient=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         )\n\u001b[1;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient \u001b[39min\u001b[39;00m (\n\u001b[1;32m    297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    298\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    300\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:2238\u001b[0m, in \u001b[0;36mIndex.is_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2205\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[1;32m   2206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_unique\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   2207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m \u001b[39m    Return if the index has unique values.\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mis_unique\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:236\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.is_unique.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:241\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._do_unique_check\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:303\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._ensure_mapping_populated\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7114\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.read_json(os.path.join(dataset_path, \"dataset\"), lines=True)\n",
    "test_dataset_df = pd.read_json(os.path.join(dataset_path, \"test_dataset\"), lines=True)\n",
    "best_response_df = pd.read_json(os.path.join(dataset_path, \"best_response\"), lines=True)\n",
    "best_response_input_df = pd.read_json(os.path.join(dataset_path, \"best_response_input\"), lines=True)\n",
    "battles_df = pd.read_json(os.path.join(dataset_path, \"battles\"), lines=True)\n",
    "n_responses_df = pd.read_json(os.path.join(dataset_path, \"n_responses\"), lines=True)\n",
    "test_match_dataset_df = pd.read_json(os.path.join(dataset_path, \"test_match_dataset\"), lines=True)\n",
    "\n",
    "dataset = dataset_df.values.tolist()\n",
    "test_dataset = test_dataset_df.values.tolist()\n",
    "best_response = best_response_df.values.tolist()\n",
    "best_response_input = best_response_input_df.values.tolist()\n",
    "n_responses = n_responses_df.values.tolist()\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    test_match_data = test_match(test_dataset)\n",
    "    test_match_dataset_df = pd.concat([test_match_dataset_df, test_match_data])\n",
    "\n",
    "    same_best_response = True\n",
    "    for i in range(3,len(test_match_data[0]),2):\n",
    "        if test_match_data[0][i][\"correct\"] == False:\n",
    "            sampled = test_match_data[0][i][\"sampled\"]\n",
    "            if sampled not in dataset_df[0].to_list():\n",
    "                content = test_match_data[0][i-1][\"prompt\"][1][\"content\"]\n",
    "                dataset.append([sampled,content,[]])\n",
    "                dataset_df = pd.DataFrame(dataset)\n",
    "                n = append_response(content, sampled, dataset)\n",
    "                n_responses.append([n])\n",
    "\n",
    "                data = battle(system_input,content,sampled,system_input,best_response_input[-1][0],best_response[-1][0]) \n",
    "                battles_df = pd.concat([battles_df,pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "\n",
    "                if data[\"Choice\"] == \"Yes\":\n",
    "                    best_response_input.append([content])\n",
    "                    best_response.append([sampled])\n",
    "                    test_dataset = [content_to_list(content,dataset)]\n",
    "                    test_dataset_df = pd.DataFrame(test_dataset)\n",
    "                    same_best_response = False\n",
    "\n",
    "    if same_best_response:\n",
    "        test_dataset0 = test_dataset.copy()\n",
    "        for t in test_dataset:\n",
    "            if t[0] != \"\":\n",
    "                if t[1] not in test_dataset_df[0].to_list():\n",
    "                    test_dataset.append(content_to_list(t[1],dataset))\n",
    "                    test_dataset_df = pd.DataFrame(test_dataset)\n",
    "            l = content_to_list(t[0], dataset)\n",
    "            for response in l[2]:\n",
    "                if response not in test_dataset_df[0].to_list():\n",
    "                    test_dataset.append(content_to_list(response,dataset))\n",
    "                    test_dataset_df = pd.DataFrame(test_dataset)\n",
    "\n",
    "    dataset_df = pd.DataFrame(dataset)\n",
    "    test_dataset_df = pd.DataFrame(test_dataset)\n",
    "    best_response_df = pd.DataFrame(best_response)\n",
    "    best_response_input_df = pd.DataFrame(best_response_input)\n",
    "    n_responses_df = pd.DataFrame(n_responses)  \n",
    "    \n",
    "    dataset_df.to_json(os.path.join(dataset_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "    test_dataset_df.to_json(os.path.join(dataset_path, \"test_dataset\"), lines=True, orient=\"records\")\n",
    "    best_response_df.to_json(os.path.join(dataset_path, \"best_response\"), lines=True, orient=\"records\")\n",
    "    best_response_input_df.to_json(os.path.join(dataset_path, \"best_response_input\"), lines=True, orient=\"records\")\n",
    "    n_responses_df.to_json(os.path.join(dataset_path, \"n_responses\"), lines=True, orient=\"records\")\n",
    "\n",
    "    pd.DataFrame(dataset_df[0]).to_json(os.path.join(dataset_path, \"dataset0\"), lines=True, orient=\"records\")\n",
    "    pd.DataFrame(dataset_df[1]).to_json(os.path.join(dataset_path, \"dataset1\"), lines=True, orient=\"records\")\n",
    "\n",
    "    battles_df.to_json(os.path.join(dataset_path, \"battles\"), lines=True, orient=\"records\")\n",
    "    test_match_dataset_df.to_json(os.path.join(dataset_path, \"test_match_dataset\"), lines=True, orient=\"records\")\n",
    "\n",
    "    responses = []\n",
    "    for responses_list in dataset_df[2]:\n",
    "        responses.append(len(responses_list))\n",
    "        pd.Series(responses)\n",
    "    responses_df = pd.DataFrame({\"len\":responses, \"responses\": dataset_df[2]})\n",
    "    responses_df.to_json(os.path.join(dataset_path, \"responses\"), lines=True, orient=\"records\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm sorry, I cannot continue the text for you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No problem! If you have any other questions or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you! I appreciate your willingness to as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're welcome! I'm glad I could help. Feel fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you! I appreciate your willingness to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you! I appreciate your offer to help. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You're welcome! I'm glad I could offer my help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thank you! I appreciate your willingness to as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thank you! I appreciate your kind words. I'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>You're welcome! I'm glad I could help. Remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>You're welcome! I'm glad I could help. Don't h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thank you! I appreciate your offer and I will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thank you! I appreciate your kind words. I'm h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thank you for your kind words! It's always rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>You're welcome! I'm glad I could help. If you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>You're welcome! I'm glad I could offer some su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>You're welcome! I'm glad I could help. Don't h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0                                                    \n",
       "1   I'm sorry, I cannot continue the text for you ...\n",
       "2   No problem! If you have any other questions or...\n",
       "3   Thank you! I appreciate your willingness to as...\n",
       "4   You're welcome! I'm glad I could help. Feel fr...\n",
       "5   Thank you! I appreciate your willingness to he...\n",
       "6   Thank you! I appreciate your offer to help. I'...\n",
       "7   You're welcome! I'm glad I could offer my help...\n",
       "8   Thank you! I appreciate your willingness to as...\n",
       "9   Thank you! I appreciate your kind words. I'll ...\n",
       "10  You're welcome! I'm glad I could help. Remembe...\n",
       "11  You're welcome! I'm glad I could help. Don't h...\n",
       "12  Thank you! I appreciate your offer and I will ...\n",
       "13  Thank you! I appreciate your kind words. I'm h...\n",
       "14  Thank you for your kind words! It's always rea...\n",
       "15  You're welcome! I'm glad I could help. If you ...\n",
       "16  You're welcome! I'm glad I could offer some su...\n",
       "17  You're welcome! I'm glad I could help. Don't h..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choice</th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>I'm sorry, I cannot continue the text for you ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\"1. The first response acknowledges the user's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Choice Instruction1                                          Response1  \\\n",
       "0    Yes               I'm sorry, I cannot continue the text for you ...   \n",
       "\n",
       "  Instruction2 Response2                                            Sampled  \n",
       "0                         \"1. The first response acknowledges the user's...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_to_list(best_response[-1][0],dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Yes',\n",
       "  '',\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  '',\n",
       "  '',\n",
       "  '\"1. The first response acknowledges the user\\'s request and provides a clear explanation of why it cannot fulfill the request.\\n2. The second response is incomplete and does not provide any information or explanation.\\n\\nBased on this reasoning, the first response is better than the second.\\n\\nYes\"}'],\n",
       " ['Yes',\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  '',\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  '\"1. Both responses acknowledge the user\\'s statement and provide a similar explanation for why the AI cannot continue the text.\\n2. Response 1 offers additional assistance and invites the user to ask any other questions or seek help with something else.\\n3. Response 2 simply restates the same explanation without any additional information or offer of assistance.\\n\\nBased on this reasoning, the first response is better than the second.\\n\\nYes\"}'],\n",
       " ['No',\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  'Thank you! I appreciate your willingness to help. I will definitely reach out if I have any further questions or need assistance.',\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  \"'1. The first response acknowledges and appreciates the willingness to help, which shows gratitude and politeness.\\n2. The first response indicates that the user will reach out if they have any further questions or need assistance, which shows a clear understanding of how to seek help.\\n3. The second response is a repetition of the initial instruction, which may not provide any additional value to the user.\\n\\nBased on these points, the first response is better than the second.\\n\\nNo'}\"],\n",
       " ['No',\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  'Thank you! I appreciate your willingness to assist. I will definitely reach out if I have any further questions or need help with anything else.',\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  \"'1. The first response acknowledges and appreciates the willingness to assist, showing gratitude.\\n2. The first response indicates that the user will reach out if they have any further questions or need help with anything else.\\n3. The second response simply repeats the initial instruction without any additional information or acknowledgement.\\n\\nBased on this reasoning, the first response is better than the second.\\n\\nNo'}\"],\n",
       " ['No',\n",
       "  'Thank you! I appreciate your willingness to help. I will definitely reach out if I have any further questions or need assistance.',\n",
       "  \"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  '\"1. Both responses acknowledge the user\\'s gratitude and express willingness to help.\\n2. Both responses encourage the user to reach out if they have any further questions or need assistance.\\n3. Both responses convey that the AI language model is available to help.\\n4. Both responses end with a positive note, wishing the user a great day or assuring them that the AI is there to help.\\n\\nBased on the above reasoning, it can be concluded that both responses are equally good. \\n\\nNo\"}'],\n",
       " ['No',\n",
       "  \"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\",\n",
       "  \"Thank you! I appreciate your offer to help. I'll definitely keep that in mind and reach out if I need any further assistance. Have a wonderful day too!\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  '\"1. Both responses acknowledge the user\\'s message and express gratitude.\\n2. Both responses offer assistance and encourage the user to reach out if they have any further questions or need help.\\n3. Both responses end with a positive and friendly closing statement.\\n\\nBased on the above reasoning, it can be concluded that both responses are equally good. \\n\\nNo\"}'],\n",
       " ['No',\n",
       "  'Thank you! I appreciate your willingness to assist. I will definitely reach out if I have any further questions or need help with anything else.',\n",
       "  \"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  '\"1. Both responses acknowledge the user\\'s gratitude and appreciation.\\n2. Both responses offer assistance and encourage the user to reach out if they have any further questions or need help.\\n3. Both responses express availability and willingness to help.\\n4. Both responses end on a positive note, wishing the user a great day or offering further assistance.\\n\\nBased on the above reasoning, it can be concluded that both responses are equally good. \\n\\nNo\"}'],\n",
       " ['No',\n",
       "  \"Thank you! I appreciate your offer to help. I'll definitely keep that in mind and reach out if I need any further assistance. Have a wonderful day too!\",\n",
       "  \"You're welcome! I'm glad I could offer my help. Don't hesitate to reach out if you need anything in the future. Have a fantastic day as well!\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  '\"1. Both responses acknowledge the user\\'s message and express gratitude or understanding.\\n2. Response 1 offers further assistance and encourages the user to reach out if needed, while Response 2 offers assistance with other questions or needs.\\n3. Response 1 ends with a positive and friendly wish for the user to have a fantastic day, while Response 2 does not include a similar closing statement.\\n\\nBased on these points, the first response is better than the second because it provides more specific and helpful information, and ends with a positive and friendly note.\\n\\nNo\"}']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "battles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  None,\n",
       "  [\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\"]],\n",
       " [\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  '',\n",
       "  [\"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\"]],\n",
       " [\"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  ['Thank you! I appreciate your willingness to help. I will definitely reach out if I have any further questions or need assistance.',\n",
       "   'Thank you! I appreciate your willingness to assist. I will definitely reach out if I have any further questions or need help with anything else.']],\n",
       " ['Thank you! I appreciate your willingness to help. I will definitely reach out if I have any further questions or need assistance.',\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  [\"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\"]],\n",
       " ['Thank you! I appreciate your willingness to assist. I will definitely reach out if I have any further questions or need help with anything else.',\n",
       "  \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  [\"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\"]],\n",
       " [\"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\",\n",
       "  'Thank you! I appreciate your willingness to help. I will definitely reach out if I have any further questions or need assistance.',\n",
       "  [\"Thank you! I appreciate your offer to help. I'll definitely keep that in mind and reach out if I need any further assistance. Have a wonderful day too!\"]],\n",
       " [\"Thank you! I appreciate your offer to help. I'll definitely keep that in mind and reach out if I need any further assistance. Have a wonderful day too!\",\n",
       "  \"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\",\n",
       "  [\"You're welcome! I'm glad I could offer my help. Don't hesitate to reach out if you need anything in the future. Have a fantastic day as well!\"]],\n",
       " [\"You're welcome! I'm glad I could help. Feel free to reach out anytime you need assistance or have more questions. I'm here to help. Have a great day!\",\n",
       "  'Thank you! I appreciate your willingness to assist. I will definitely reach out if I have any further questions or need help with anything else.',\n",
       "  []],\n",
       " [\"You're welcome! I'm glad I could offer my help. Don't hesitate to reach out if you need anything in the future. Have a fantastic day as well!\",\n",
       "  \"Thank you! I appreciate your offer to help. I'll definitely keep that in mind and reach out if I need any further assistance. Have a wonderful day too!\",\n",
       "  []]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(test_match_data[0])-2)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " None,\n",
       " [\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate content on behalf of individuals.\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\"]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       " \"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  '',\n",
       "  [\"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\"]],\n",
       " ['',\n",
       "  None,\n",
       "  [\"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\"]],\n",
       " [\"No problem! If you have any other questions or need assistance with something else, feel free to ask. I'm here to help!\",\n",
       "  \"I'm sorry, I cannot continue the text for you as I am an AI language model and I do not have access to personal information or the ability to generate text on behalf of someone else.\",\n",
       "  []]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': ''},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'correct': False, 'expected': [], 'picked': N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                               None\n",
       "1                                               None\n",
       "2  {'prompt': [{'role': 'system', 'content': ''},...\n",
       "3  {'correct': False, 'expected': [], 'picked': N..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test_match() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(dataset_test)):\n\u001b[1;32m      3\u001b[0m     test_match_data \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     test_match_data\u001b[39m.\u001b[39mappend(test_match(dataset_test[d][\u001b[39m0\u001b[39;49m],dataset_test[d][\u001b[39m2\u001b[39;49m]))\n\u001b[1;32m      5\u001b[0m dataset_test\u001b[39m.\u001b[39mappend(dataset(dataset[:][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mindex(dataset_test[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])))\n",
      "\u001b[0;31mTypeError\u001b[0m: test_match() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for d in range(0,len(dataset_test)):\n",
    "    test_match_data = []\n",
    "    test_match_data.append(test_match(dataset_test[d][0],dataset_test[d][2]))\n",
    "dataset_test.append(dataset(dataset[:][0].index(dataset_test[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.append([])\n",
    "for u in user_content:\n",
    "    data = battle(system_input1,u,system_input2,best_response_input)\n",
    "    if data[\"Choice\"] == \"Yes\":\n",
    "        best_response_input = data[\"Instruction1\"]\n",
    "        best_response.append(data[\"Response1\"]) \n",
    "    dataset[u].append(data)\n",
    "user_content.append(data[\"Response1\"])\n",
    "df = pd.DataFrame(dataset)\n",
    "user_content_df = pd.DataFrame(user_content)\n",
    "df.to_json(os.path.join(os.getcwd(), \"battles.jsonl\"), orient=\"records\", lines=True)\n",
    "user_content_df.to_json(os.path.join(os.getcwd(), \"battles_user_content.jsonl\"), orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-shot prompt\n",
    "\n",
    "choice = int(df[\"Choice\"][0])-1\n",
    "if choice == 1:\n",
    "    input[0] = [\n",
    "        {\"role\": \"system\", \"content\": user_input[choice], \"name\": \"example_user\"},\n",
    "        {\"role\": \"system\", \"content\": df[df.columns[1+(2*choice)]][0], \"name\": \"example_assistant\"},\n",
    "        {\"role\":\"system\",\"content\":\"\"},\n",
    "        {\"role\":\"user\",\"content\":user_input[1]},\n",
    "        ]\n",
    "    dataset = [{\"input1\": input[0], \"input2\": input[1]}]\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(os.path.join(os.getcwd(), \"battles.jsonl\"), orient=\"records\", lines=True)\n",
    "    df.to_json(os.path.join(os.getcwd(), \"battles.jsonl\"), orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instruction(i):\n",
    "    if i.startswith(\"User: \"):\n",
    "        input = [{\"role\":\"system\",\"content\":\"\"},{\"role\":\"user\",\"content\":i.removeprefix(\"User: \")}]\n",
    "    else:\n",
    "        ins = i.split(\"\\nUser: \")\n",
    "        input = [{\"role\":\"system\",\"content\":ins[0]},{\"role\":\"user\",\"content\":ins[1]}]\n",
    "    return input\n",
    "meta = []\n",
    "for index, row in df.iterrows():\n",
    "    meta.append({\"input1\": instruction(row[0]), \"completion1\": row[1], \"input2\": instruction(row[2]), \"completion2\": row[3], \"choice\":\"\"})\n",
    "meta = pd.DataFrame(meta)\n",
    "\n",
    "row = 5\n",
    "meta.iloc[row][0],meta.iloc[row][1],meta.iloc[row][2],meta.iloc[row][3]\n",
    "\n",
    "meta.iloc[row][4] = \"1\"\n",
    "#meta.to_json(meta_path, orient=\"records\", lines=True)\n",
    "!oaieval gpt-3.5-turbo dataset-meta --record_path /workspaces/evals/evallogs/logs-meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
